{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90fca9d-114b-4722-9886-67fd04fea6fc",
   "metadata": {},
   "source": [
    "## L2 DataFrame APIs (Transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ce9262e-4d21-4cc8-9181-8200f8697587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d96aa2ae-5f43-43df-b6e4-9cfedcd0ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark Training - DF APIs\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83ee42b-1a96-437e-a0c2-fee511fd449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord = spark.read.load('PracticeFiles/Orders', sep=',', format='csv', schema=('order_id int,order_date timestamp, order_customer_id int, order_status string'))\n",
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355553e3-3614-4a8a-8885-a3bcb05b7911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|   Ram|    31|    33|    29|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Robert', 35, 40, 40), ('Robert', 35, 40, 40),('Ram', 31, 33, 29),('Ram', 31, 33, 29)]\n",
    "emp = spark.createDataFrame(data=data, schema=['name', 'score1','score2', 'score3'])\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fc822-76bb-4366-a009-84ba26ddba99",
   "metadata": {},
   "source": [
    "## 1. select API\n",
    "\n",
    "- For selecting one or more columns\n",
    "- Allows you apply functions on selected columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da560b-5f9f-4797-bcad-2ed29978b4a7",
   "metadata": {},
   "source": [
    "### 1.1. Selecting one/multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "791741c8-20a4-4a86-af76-9b1e2f0c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+\n",
      "|order_id|order_id|order10|\n",
      "+--------+--------+-------+\n",
      "|       1|       1|     11|\n",
      "|       2|       2|     12|\n",
      "|       3|       3|     13|\n",
      "|       4|       4|     14|\n",
      "|       5|       5|     15|\n",
      "+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 methods of using it as outlined in script below\n",
    "ord.select(ord.order_id, 'order_id', (ord.order_id + 10).alias('order10')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733c7b7-3f8d-4111-bdb4-683fd4a30b04",
   "metadata": {},
   "source": [
    "### 1.2 Applying functions on selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2ae1bc-e4af-48ae-889f-0ed5cbe2c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|   order_status|lower(order_status)|\n",
      "+---------------+-------------------+\n",
      "|         CLOSED|             closed|\n",
      "|PENDING_PAYMENT|    pending_payment|\n",
      "|       COMPLETE|           complete|\n",
      "|         CLOSED|             closed|\n",
      "|       COMPLETE|           complete|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select('order_status',F.lower(ord.order_status)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068733b-6fd8-46ea-ab02-c860929c9b19",
   "metadata": {},
   "source": [
    "## 2. selectExpr()\n",
    "\n",
    "- A variant of the selct api that accepst SQL expressions\n",
    "- Advantage: Comes in handy when you want to perform an operation that has no built-in Spark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f55520-a6f2-45b0-a6fc-8aa88afaa271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d2e196-8646-4d5a-9735-66c1cd50534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|order_year|\n",
      "+----------+\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first using normal select api\n",
    "ord.select(F.substring(ord.order_date, 1, 4).alias('order_year')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "198edd0d-36ed-44c5-ac7d-a9d82bb609c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|order_year|\n",
      "+----------+\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# then using selectExpr\n",
    "ord.selectExpr(\"substring(order_date, 1,4) as order_year\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e46c3-7797-48fb-8d39-93644baee5d7",
   "metadata": {},
   "source": [
    "## 3. withColumn(colName, col)\n",
    "- Applies transformation to only selected columns\n",
    "- First arg is the alias name. If we give an alias name same as the column name, the transformation will be applied on the same column\n",
    "- otherwise a new column will be formed. Avoid giving an existing column name as alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a88e0a7-d8c3-4ddf-9e0a-2bcf607eeb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2bfc6c6-4f57-4357-8d39-594524413dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|order_year|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|      2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|      2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|      2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|      2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|      2013|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create a new columns called order_year\n",
    "ord.withColumn('order_year', F.substring(ord.order_date, 1,4)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "791980a3-3d2a-4007-ab52-0105686693fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|      2013|            11599|         CLOSED|\n",
      "|       2|      2013|              256|PENDING_PAYMENT|\n",
      "|       3|      2013|            12111|       COMPLETE|\n",
      "|       4|      2013|             8827|         CLOSED|\n",
      "|       5|      2013|            11318|       COMPLETE|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets modify existing column order_date\n",
    "ord.withColumn('order_date', F.substring(ord.order_date, 1,4)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d033b27-678c-4bb1-9f43-f9638ec37633",
   "metadata": {},
   "source": [
    "## 4. withColumnRenamed(existingCol, newCol)\n",
    "\n",
    "Renames and existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "971411b9-637c-43c6-a2e7-d542215c5b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+---------------+\n",
      "|order_id1|         order_date|order_customer_id|   order_status|\n",
      "+---------+-------------------+-----------------+---------------+\n",
      "|        1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|        2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|        3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|        4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|        5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+---------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumnRenamed('order_id', 'order_id1').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9865aeb-f375-493f-a6eb-b8d7475e5dcc",
   "metadata": {},
   "source": [
    "## 5. drop(*cols)\n",
    "\n",
    "- Takes one or more columns as argument and drops them\n",
    "- Do not pass in a list except you unpack with *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e0ed27-9e28-43f8-89fe-bd4ed815168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+---------------+\n",
      "|order_id|order_customer_id|   order_status|\n",
      "+--------+-----------------+---------------+\n",
      "|       1|            11599|         CLOSED|\n",
      "|       2|              256|PENDING_PAYMENT|\n",
      "|       3|            12111|       COMPLETE|\n",
      "|       4|             8827|         CLOSED|\n",
      "|       5|            11318|       COMPLETE|\n",
      "+--------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord_new = ord.drop('order', 'order_date')\n",
    "ord_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d2990-fe1a-4d65-94b3-16ef87a10f3f",
   "metadata": {},
   "source": [
    "## 6. dropDuplicates(subset=None)\n",
    "- Drop duplicate rows.\n",
    "- Optionally can consider only subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5a5c20d-1a09-45f4-8026-5ebe1a0572f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|   Ram|    31|    33|    29|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets inspect the duplicates\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67b7004b-d8c9-4843-881d-dfd60424a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's drop duplicate rows\n",
    "emp.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "703dabdd-ba4d-46e2-b244-a72a1331d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|   Ram|    31|    33|    29|\n",
      "|Robert|    35|    40|    40|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets drop rows with duplicate name - score1 pairs\n",
    "emp.dropDuplicates(subset = ['name','score1']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9add529-8c21-4b5a-a3ef-3c96546fffc3",
   "metadata": {},
   "source": [
    "## 7. Filter: (also where)\n",
    "- Already visited - see lesson 1\n",
    "- use `&` for 'and' and `|` for 'or'\n",
    "- use column function `isin` for multiple search\n",
    "- use IN operator for sql style syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3002362c-d405-4ec2-9571-ae442e625e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|      CLOSED|\n",
      "|       3|2013-07-25 00:00:00|            12111|    COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|      CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|    COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|    COMPLETE|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normal syntax vs sql syntax\n",
    "ord.where(ord.order_status.isin('COMPLETE','CLOSED')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34b79d65-6ad0-461b-b987-c285bfd4e3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|      CLOSED|\n",
      "|       3|2013-07-25 00:00:00|            12111|    COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|      CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|    COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|    COMPLETE|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql-like syntax as we've already visited the others\n",
    "ord.where(\"order_status in ('COMPLETE','CLOSED')\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a36f2-b788-479d-a9da-f88abe4a3add",
   "metadata": {},
   "source": [
    "## 8. sort() or orderBy() APIs\n",
    "- very costly operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e15e513c-9605-4df8-acd9-07243e832028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method 1\n",
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f444638f-29be-4030-af4d-97310cc93666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|   22945|2013-12-13 00:00:00|                1|       COMPLETE|\n",
      "|   57963|2013-08-02 00:00:00|                2|        ON_HOLD|\n",
      "|   15192|2013-10-29 00:00:00|                2|PENDING_PAYMENT|\n",
      "|   67863|2013-11-30 00:00:00|                2|       COMPLETE|\n",
      "|   33865|2014-02-18 00:00:00|                2|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort by order_customer_id\n",
    "ord.sort(ord.order_customer_id.asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ba7f474-71e0-4b21-bd3c-6024ef19fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|   57617|2014-07-24 00:00:00|                3|    COMPLETE|\n",
      "|   57733|2014-07-24 00:00:00|               17|      CLOSED|\n",
      "|   57684|2014-07-24 00:00:00|               98|    COMPLETE|\n",
      "|   57695|2014-07-24 00:00:00|              112|    COMPLETE|\n",
      "|   57598|2014-07-24 00:00:00|              138|     PENDING|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.sort(ord.order_date.desc(), ord.order_customer_id.asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49df90b7-5a10-4188-b378-9ef7c3bfa9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|   57617|2014-07-24 00:00:00|                3|    COMPLETE|\n",
      "|   57733|2014-07-24 00:00:00|               17|      CLOSED|\n",
      "|   57684|2014-07-24 00:00:00|               98|    COMPLETE|\n",
      "|   57695|2014-07-24 00:00:00|              112|    COMPLETE|\n",
      "|   57598|2014-07-24 00:00:00|              138|     PENDING|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method 2: using the ascending= argument\n",
    "ord.sort(ord.order_date, ord.order_customer_id, ascending= [0, 1]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69420bbc-2e0c-43ba-b7ec-55bd4632b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|   57617|2014-07-24 00:00:00|                3|    COMPLETE|\n",
      "|   57733|2014-07-24 00:00:00|               17|      CLOSED|\n",
      "|   57684|2014-07-24 00:00:00|               98|    COMPLETE|\n",
      "|   57695|2014-07-24 00:00:00|              112|    COMPLETE|\n",
      "|   57598|2014-07-24 00:00:00|              138|     PENDING|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or using pass True/False in ascending=\n",
    "ord.sort(ord.order_date, ord.order_customer_id, ascending= [False, True]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32e032-4dc9-4c9f-813e-8c76c504f6ce",
   "metadata": {},
   "source": [
    "## 9. sortWithinPartitions\n",
    "Used to avoid sorting globally (like above), but rather sort within a group/partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21896a4f-3c7e-4ba1-977b-2c04d5c4608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   d|   4|\n",
      "|   c|   3|\n",
      "|   b|   2|\n",
      "|   e|   5|\n",
      "|   f|  10|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('a',1), ('d',4), ('c', 3), ('b', 2), ('e', 5), ('f',10)]\n",
    "df = spark.createDataFrame(data=data, schema='col1 string, col2 int')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb0b430b-cca5-409d-b24d-26e564f13f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's repartition to 3 partitions\n",
    "df = df.repartition(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a254b44-6f39-420b-8a0e-39b56f650db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many partitions are there in the data\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dce73515-de79-48ac-931f-3e94485081de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(col1='c', col2=3), Row(col1='b', col2=2)],\n",
       " [Row(col1='a', col2=1)],\n",
       " [Row(col1='d', col2=4), Row(col1='e', col2=5), Row(col1='f', col2=10)]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how's the data distributed in these 8 partitions\n",
    "df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "002a290a-48e2-4e82-9b0e-c849c78e3910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "|   d|   4|\n",
      "|   e|   5|\n",
      "|   f|  10|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using normal sort\n",
    "df.sort(df.col1.asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baf424-0da0-4ed7-b975-c8bf46ded8c8",
   "metadata": {},
   "source": [
    "This has sorted it globally, i.e. every value of col1 has been sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3da0044-af03-4dfb-924a-d672d1bafe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "|   a|   1|\n",
      "|   d|   4|\n",
      "|   e|   5|\n",
      "|   f|  10|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using sortWithinPartition\n",
    "df.sortWithinPartitions(df.col1.asc(), ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5d2d9-04bd-4942-8ae8-c36af17ac69b",
   "metadata": {},
   "source": [
    "So now if you extract this data into 3 files, each of those 3 files will be sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25066d-7422-4131-90d2-4fe0ae8c2afb",
   "metadata": {},
   "source": [
    "## 10. Set Operator APIs\n",
    "- union() and unionAll()\n",
    "- unionByName()\n",
    "- intersect() and intersectAll()\n",
    "- exceptAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155d568-bbdd-46b4-b871-77e430b3817f",
   "metadata": {},
   "source": [
    "#### 10.1 union() and unionAll()\n",
    "- Behave in same manner, retains duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3539d44-2e0b-4ce6-a46b-3d6f84f2d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df\n",
    "df1 = spark.range(10)\n",
    "df2 = spark.range(5,15)\n",
    "df1.show(), df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48b6ff-0848-419e-a222-f50a7143d7e7",
   "metadata": {},
   "source": [
    "`notice:` 5 - 9 are common to both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bf06858-333f-40e5-9a27-13f0f277328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()\n",
    "# `Notice:` 5 - 9 repeat once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1380da-bece-4f7c-9533-2c41db54107b",
   "metadata": {},
   "source": [
    "#### 10.2 unionByName()\n",
    "- This function differst to the union in that it resolves functions by name (not by position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f73c5d7-d57e-43b3-b8fb-98b2afb09e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   d|   4|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n",
      "+----+----+\n",
      "|col2|col1|\n",
      "+----+----+\n",
      "|   2|   b|\n",
      "|   5|   e|\n",
      "|  10|   f|\n",
      "+----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = [('a',1), ('b', 2), ('d',4), ('c', 3)]\n",
    "data2 = [(2, 'b'), (5, 'e'), (10, 'f')]\n",
    "df1 = spark.createDataFrame(data=data1, schema='col1 string, col2 int')\n",
    "df2 = spark.createDataFrame(data=data2, schema='col2 int, col1 string')\n",
    "df1.show(), df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd60db2-7346-42ed-b605-4b920947c55d",
   "metadata": {},
   "source": [
    "notice ordering of columns for \n",
    "- df1: col1 and col2\n",
    "- df2: col2 and col1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66b2463d-899a-42cd-917f-078981593bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   d|   4|\n",
      "|   c|   3|\n",
      "|   2|   b|\n",
      "|   5|   e|\n",
      "|  10|   f|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union() combines by column positions and not column names\n",
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc3747b8-dd86-4568-939b-11be753755ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   d|   4|\n",
      "|   c|   3|\n",
      "|   b|   2|\n",
      "|   e|   5|\n",
      "|   f|  10|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in these situations, we should be using unionByName()\n",
    "df1.unionByName(df2).show()\n",
    "# However notice distinct are retained e.g. b, 2. Use distinct() to dedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e7e5-3f92-4ff4-ad54-cb7e9cf9f0a3",
   "metadata": {},
   "source": [
    "#### 10.3 intersect() and intersectAll()\n",
    "\n",
    "- intersect() should remove duplicates while intersectAll() doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0921e7c6-c500-401c-85ac-38bc6a4c5dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df\n",
    "df1 = spark.range(10)\n",
    "df2 = spark.range(5,15)\n",
    "df1.show(), df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c665c09-ab66-460f-8811-97bee9bcd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08fbf742-831f-4a5c-9ee8-7545043e8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  7|\n",
      "|  6|\n",
      "|  9|\n",
      "|  5|\n",
      "|  8|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersectAll(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbba46-387d-4a75-aca9-9068c0e699a8",
   "metadata": {},
   "source": [
    "#### 10.4 exceptAll()\n",
    "- Returns rows present in base dataframe but not in the another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e97f362d-d613-4992-816f-8bab08b7d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  3|\n",
      "|  2|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3a3aa-19da-4974-abde-0be5cd942ec3",
   "metadata": {},
   "source": [
    "## 11. Join APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c9198198-6130-41f7-9752-feb40dc45751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|empname|\n",
      "+-----+-------+\n",
      "|    1| Robert|\n",
      "|    2|    Ria|\n",
      "|    3|  James|\n",
      "+-----+-------+\n",
      "\n",
      "+-----+-------+\n",
      "|empid|country|\n",
      "+-----+-------+\n",
      "|    2|    USA|\n",
      "|    4|  India|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(data= [(1, 'Robert'),(2, 'Ria'), (3, 'James')], schema='empid int, empname string')\n",
    "df2 = spark.createDataFrame(data= [(2, 'USA'),(4, 'India')], schema = 'empid int, country string')\n",
    "\n",
    "df1.show(), df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ade31-e28a-4242-9be1-36f62fa78732",
   "metadata": {},
   "source": [
    "#### 11.1 inner join\n",
    "- for multi column joins, on = (condition1) & (condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2c430789-de08-4446-a01f-d2f21739df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    2|    Ria|    2|    USA|\n",
      "+-----+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inner join = the default\n",
    "# for multi column joins, on = (condition1) & (condition2)\n",
    "df1.join(df2, df1.empid == df2.empid).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "00533451-301d-4902-80fc-be967ed6cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|empid|empname|country|\n",
      "+-----+-------+-------+\n",
      "|    2|    Ria|    USA|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inner join, selecting just a couple of columns\n",
    "df1.join(df2, df1.empid == df2.empid).select(df1.empid, df1.empname, df2.country).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcf816-4f9e-4df5-8f93-721a66b5b3b6",
   "metadata": {},
   "source": [
    "#### 11.2 Left outer (similar syntax for right join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a3d1afc-42aa-4b28-bc98-d12e9a95fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|empid|empname|country|\n",
      "+-----+-------+-------+\n",
      "|    1| Robert|   null|\n",
      "|    3|  James|   null|\n",
      "|    2|    Ria|    USA|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, df1.empid == df2.empid, how='left').select(df1.empid, df1.empname, df2.country).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b6491-c32a-4390-bf0b-3f894058fba2",
   "metadata": {},
   "source": [
    "### 11.3 Full join\n",
    "\n",
    "- Get all records from both tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f508181-4b3b-4075-9261-dfd3506da815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|empid|empname|country|\n",
      "+-----+-------+-------+\n",
      "|    1| Robert|   null|\n",
      "|    3|  James|   null|\n",
      "| null|   null|  India|\n",
      "|    2|    Ria|    USA|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, df1.empid == df2.empid, how='full').select(df1.empid, df1.empname, df2.country).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ceae6-8aa2-430f-8a9d-44ff2776c5b7",
   "metadata": {},
   "source": [
    "#### 11.4 left anti\n",
    "\n",
    "- Returns records present in left table but not in the right table\n",
    "- `Note:` With this join, you cannot select a column from the right dataframe. You can only select from the left one. This is because it only checks the left df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "97818e94-4f20-4e65-a793-af17c7fd8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|empname|\n",
      "+-----+-------+\n",
      "|    1| Robert|\n",
      "|    3|  James|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, df1.empid == df2.empid, how='left_anti').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f95a3-1dbd-45fd-ba09-9a93b4d89ea4",
   "metadata": {},
   "source": [
    "#### 11.5 left semi\n",
    "- Similar to inner join but much faster/efficient\n",
    "- `Difference:` this only broadcasts/checks the columns in the left dataframe. So you cannot retrieve any columns from right dataframe\n",
    "- `When to use it:` If you dont require a column from the right table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2b468c81-a481-4b86-bd05-c31f0e96192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|empname|\n",
      "+-----+-------+\n",
      "|    1| Robert|\n",
      "|    2|    Ria|\n",
      "|    3|  James|\n",
      "+-----+-------+\n",
      "\n",
      "+-----+-------+\n",
      "|empid|country|\n",
      "+-----+-------+\n",
      "|    2|    USA|\n",
      "|    4|  India|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.show(), df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ffa5c215-16b1-462d-af0f-edea094f3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|empname|\n",
      "+-----+-------+\n",
      "|    2|    Ria|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, df1.empid == df2.empid, how='leftsemi').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e0124-43da-4f9a-bc66-c9991c6f9568",
   "metadata": {},
   "source": [
    "#### 11.6 self join\n",
    "- Not an API\n",
    "- Just to show how to perform it in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42c9d51f-beba-465a-8ee8-7de3ac8bd7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+\n",
      "|empid|empname|managerid|\n",
      "+-----+-------+---------+\n",
      "|    1| Robert|        2|\n",
      "|    2|    Ria|        3|\n",
      "|    3|  James|        5|\n",
      "+-----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data= [(1, 'Robert', 2),(2, 'Ria', 3), (3, 'James', 5)], schema='empid int, empname string, managerid int')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4e9ad57c-5b3e-42eb-9bb1-033c42b70318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+------------+\n",
      "|empid|empname|managerid|manager_name|\n",
      "+-----+-------+---------+------------+\n",
      "|    3|  James|        3|         Ria|\n",
      "|    2|    Ria|        2|      Robert|\n",
      "+-----+-------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's get manager names - note: if you dont use the F.col function, spark throws an error\n",
    "df.alias('df_left')\\\n",
    "    .join(df.alias('df_right'), F.col('df_left.empid')==F.col('df_right.managerid'), 'inner')\\\n",
    "    .select(F.col('df_left.empid'), F.col('df_left.empname'), F.col('df_right.managerid'), F.col('df_right.empname').alias('manager_name'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10fa7f-2704-4901-b531-0d972200b622",
   "metadata": {},
   "source": [
    "## 12. Aggregation APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b9565313-6a34-4428-82b8-ccc94f04c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+--------+--------+------+\n",
      "|order_item_id|order_item_order_id|order_item_proeuct_id|quantity|subtotal| price|\n",
      "+-------------+-------------------+---------------------+--------+--------+------+\n",
      "|            1|                  1|                  957|       1|  299.98|299.98|\n",
      "|            2|                  2|                 1073|       1|  199.99|199.99|\n",
      "|            3|                  2|                  502|       5|   250.0|  50.0|\n",
      "|            4|                  2|                  403|       1|  129.99|129.99|\n",
      "|            5|                  4|                  897|       2|   49.98| 24.99|\n",
      "+-------------+-------------------+---------------------+--------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderItem = spark.read.load('PracticeFiles/Order_items', sep=',', format='csv', schema='order_item_id int, order_item_order_id int, order_item_proeuct_id int, quantity int, subtotal float, price float')\n",
    "orderItem.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d445ac-2c47-453c-9352-c665d345a8ae",
   "metadata": {},
   "source": [
    "#### 12.1 summary function\n",
    "\n",
    "- Displays basic summary functions for all numeric fields i.e. count, mean, stddev, min, 25, 50, 75 and max percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e029dd33-d752-4c2c-8b9e-fba1ac932174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+---------------------+------------------+------------------+------------------+\n",
      "|summary|    order_item_id|order_item_order_id|order_item_proeuct_id|          quantity|          subtotal|             price|\n",
      "+-------+-----------------+-------------------+---------------------+------------------+------------------+------------------+\n",
      "|  count|           172198|             172198|               172198|            172198|            172198|            172198|\n",
      "|   mean|          86099.5|  34442.56682423721|    660.4877176273824|2.1821275508426345|199.32066922046081|133.75906959048717|\n",
      "| stddev|49709.42516431533| 19883.325171992343|     310.514472790008|1.4663523175387134|112.74303987146804|118.55893633258484|\n",
      "|    min|                1|                  1|                   19|                 1|              9.99|              9.99|\n",
      "|    25%|            43033|              17204|                  403|                 1|            119.98|              50.0|\n",
      "|    50%|            86085|              34464|                  627|                 1|            199.92|             59.99|\n",
      "|    75%|           129134|              51682|                 1004|                 3|            299.95|            199.99|\n",
      "|    max|           172198|              68883|                 1073|                 5|           1999.99|           1999.99|\n",
      "+-------+-----------------+-------------------+---------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for all numeric fields\n",
    "orderItem.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "98b3b683-0ce4-4560-b24f-41befadf3d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|          quantity|          subtotal|             price|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            172198|            172198|            172198|\n",
      "|   mean|2.1821275508426345|199.32066922046081|133.75906959048717|\n",
      "| stddev|1.4663523175387134|112.74303987146804|118.55893633258484|\n",
      "|    min|                 1|              9.99|              9.99|\n",
      "|    25%|                 1|            119.98|              50.0|\n",
      "|    50%|                 1|            199.92|             59.99|\n",
      "|    75%|                 3|            299.95|            199.99|\n",
      "|    max|                 5|           1999.99|           1999.99|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for only a subset of fields\n",
    "orderItem.select(orderItem.quantity, orderItem.subtotal, orderItem.price).summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e7652-afbb-406e-89db-e66ae4a4bf59",
   "metadata": {},
   "source": [
    "#### 12.2 average, min, max, median etc\n",
    "- Available from pyspark.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "523ace89-def7-4955-bade-1db27d24e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(price)|\n",
      "+------------------+\n",
      "|133.75906959048717|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderItem.select(F.avg(orderItem.price)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "42dc4571-8bf8-4750-8b3e-c4af04b3d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|avg_price|\n",
      "+---------+\n",
      "|   133.76|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# round and rename field\n",
    "orderItem.select(F.round(F.avg(orderItem.price), 2).alias('avg_price')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f61db9-d1ab-4e18-b38d-c73ac8b39342",
   "metadata": {},
   "source": [
    "#### 12.3 sum and sumDistinct\n",
    "- sum just adds up everything\n",
    "- sumDistinct first removes duplicates before summing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "53bafa65-a18c-4d8d-8a5a-7f24a3b3cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------+\n",
      "|round(sum(price), 2)|round(sum(DISTINCT price), 2)|\n",
      "+--------------------+-----------------------------+\n",
      "|       2.303304427E7|                      9832.42|\n",
      "+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderItem.select(F.round(F.sum(orderItem.price),2), F.round(F.sumDistinct(orderItem.price),2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85948942-7be4-4913-b7e5-afebac148eb6",
   "metadata": {},
   "source": [
    "#### 12.4 count and countDistinct\n",
    "- similar explanation as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f9f34c8d-12ab-4144-9a8f-984c8aa27a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+\n",
      "|count(price)|count(DISTINCT price)|\n",
      "+------------+---------------------+\n",
      "|      172198|                   57|\n",
      "+------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderItem.select(F.count(orderItem.price), F.countDistinct(orderItem.price)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee13c0-0965-4841-911b-85774a01c065",
   "metadata": {},
   "source": [
    "#### 12.5 first and last\n",
    "- min and max can be used in their place expecially for numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4165e77b-a499-4ff0-8dc2-1b32211deff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+--------+--------+-------+\n",
      "|order_item_id|order_item_order_id|order_item_proeuct_id|quantity|subtotal|  price|\n",
      "+-------------+-------------------+---------------------+--------+--------+-------+\n",
      "|       171961|              68778|                  208|       1| 1999.99|1999.99|\n",
      "|       172129|              68848|                  208|       1| 1999.99|1999.99|\n",
      "|       172019|              68806|                  208|       1| 1999.99|1999.99|\n",
      "|       171765|              68703|                  208|       1| 1999.99|1999.99|\n",
      "|       172032|              68809|                  208|       1| 1999.99|1999.99|\n",
      "+-------------+-------------------+---------------------+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "orderItem.sort(orderItem.price.desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8848fc34-82e8-42d3-a254-0537f464cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|first(price)|\n",
      "+------------+\n",
      "|     1999.99|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's get highest price\n",
    "orderItem.sort(orderItem.price.desc()).select(F.first(orderItem.price)).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015a66f-977a-46d6-851b-6c577024bfa8",
   "metadata": {},
   "source": [
    "#### 12.6 collect_set, collect_list\n",
    "- does what the names say. Sets contain unique elements while lists dont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "af8f7b5a-ae4e-40e8-85a3-d5f438fd7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|salary|\n",
      "+---+------+\n",
      "|  1|   100|\n",
      "|  2|   150|\n",
      "|  3|   200|\n",
      "|  4|    50|\n",
      "|  5|    50|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(1,100),(2,150),(3,200),(4,50),(5,50)], schema='id int, salary int')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "97937e83-b0df-409f-9f80-604295fe303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+\n",
      "|list                   |set                |\n",
      "+-----------------------+-------------------+\n",
      "|[100, 150, 200, 50, 50]|[150, 100, 50, 200]|\n",
      "+-----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show(truncate=False) shows every element in field\n",
    "df.select(F.collect_list(df.salary).alias('list'), F.collect_set(df.salary).alias('set')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ee159d81-c04a-4ff8-b6ce-159134dbdaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|first_sal|second_sal|\n",
      "+---------+----------+\n",
      "|      150|        50|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets access first and second distinct salary\n",
    "df.select(F.collect_list(df.salary)[1].alias('first_sal'), F.collect_set(df.salary)[2].alias('second_sal')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa87ee-4039-4804-8975-d4a93a338ad1",
   "metadata": {},
   "source": [
    "#### 12.7 skewness, variance and stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a3d48ec2-f1d8-4d63-9100-7cb4686b4b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-----------------+\n",
      "|      skewness_sal|var_sal|        stdev_sal|\n",
      "+------------------+-------+-----------------+\n",
      "|0.3631734744194305| 4250.0|65.19202405202648|\n",
      "+------------------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.skewness(df.salary).alias('skewness_sal'), F.variance(df.salary).alias('var_sal'), F.stddev(df.salary).alias('stdev_sal')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad7a28-91e5-4d23-b2df-631d4469b927",
   "metadata": {},
   "source": [
    "## 13 GroupBy API\n",
    "The functions below can be used to create GroupedData object:\n",
    "- avg(), count(), min(), max(), sum(), agg(), pivot(), apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5cac644d-b71f-474c-9b3d-2aaed4416756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('James', 'Sales', 'NY', 900, 34),\n",
    "    ('Robert', 'Sales', 'CA', 8100, 30),\n",
    "    ('Lisa', 'Finance', 'CA', 9000, 24),\n",
    "    ('Deja', 'Finance', 'CA', 9900, 40),\n",
    "    ('Sugie', 'Finance', 'NY', 8300, 36),\n",
    "    ('Ram', 'Finance', 'NY', 7900, 53),\n",
    "    ('Kyle', 'Marketing', 'CA', 8000, 25),\n",
    "    ('Reid', 'Marketing', 'NY', 9100, 50)\n",
    "]\n",
    "\n",
    "schema = ['empname', 'dept', 'state', 'salary', 'age']\n",
    "df = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "050a91b9-075e-4733-852b-e96ef68fa3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|   900| 34|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "366f0fca-2a44-42b5-9e3e-aab542f31496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x16453a220>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this creates a groupedData object\n",
    "df.groupBy(df.dept)\n",
    "# try help(df.groupBy(df.dept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096647fa-2873-42fd-852d-b4078de1e711",
   "metadata": {},
   "source": [
    "#### 13.1. Apply one function on one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "74448e7a-56f1-47aa-874e-c10aa0a55e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     dept|sum(salary)|\n",
      "+---------+-----------+\n",
      "|    Sales|       9000|\n",
      "|  Finance|      35100|\n",
      "|Marketing|      17100|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply functions on single column\n",
    "df.groupBy('dept').sum('salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb30a7-0d08-4bf2-86ed-10465ad2d196",
   "metadata": {},
   "source": [
    "#### 13.2 apply one function on multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f48b7f38-4fa9-4877-b7e1-854bfa8a48a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------+\n",
      "|     dept|min(salary)|min(age)|\n",
      "+---------+-----------+--------+\n",
      "|    Sales|        900|      30|\n",
      "|  Finance|       7900|      24|\n",
      "|Marketing|       8000|      25|\n",
      "+---------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('dept').min('salary','age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56442136-6da8-4689-a4d6-b4e771c1024c",
   "metadata": {},
   "source": [
    "### 13.3 Apply multiple aggregation functions\n",
    "- use agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "31c35298-4bf2-43da-b6cf-220d1c2449d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|   900| 34|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8d580703-92e6-4744-bc5b-b5e6c6e61bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------+-----------+\n",
      "|     dept|avg(salary)|max(age)|min(salary)|\n",
      "+---------+-----------+--------+-----------+\n",
      "|    Sales|     4500.0|      34|        900|\n",
      "|  Finance|     8775.0|      53|       7900|\n",
      "|Marketing|     8550.0|      50|       8000|\n",
      "+---------+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.groupBy(df.dept).agg(F.avg(df.salary), F.max(df.age)).show() or\n",
    "df.groupBy('dept').agg(F.avg('salary'), F.max('age'), F.min('salary')).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf39e4-8a8c-4010-b1d6-5162e93cb4c4",
   "metadata": {},
   "source": [
    "#### 13.4 Apply aggregations & use filter() or where()\n",
    "- can be applied before grouping and aggregating as in example 1 below OR\n",
    "- can be applied after grouping and aggregating as in example 2. Using and alias in this case really tidies up the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f9bb135-3b00-4c4c-9a99-3a5d3c434803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------+-----------+\n",
      "|state|avg(salary)|max(age)|min(salary)|\n",
      "+-----+-----------+--------+-----------+\n",
      "|   CA|     9450.0|      40|       9000|\n",
      "|   NY|     8100.0|      53|       7900|\n",
      "+-----+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "df.filter(df.dept=='Finance')\\\n",
    "    .groupBy('state')\\\n",
    "    .agg(F.avg('salary'), F.max('age'), F.min('salary'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d37ccb24-fa1b-4009-8588-94be42bc758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-------+\n",
      "|     dept|avg_sal|max_sal|min_sal|\n",
      "+---------+-------+-------+-------+\n",
      "|  Finance| 8775.0|     53|   7900|\n",
      "|Marketing| 8550.0|     50|   8000|\n",
      "+---------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method 2 - use F.col on aliased columns\n",
    "df.groupBy('dept')\\\n",
    "    .agg(F.avg('salary').alias('avg_sal'), F.max('age').alias('max_sal'), F.min('salary').alias('min_sal'))\\\n",
    "    .where(F.col('min_sal')>7_000)\\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2beb98-7fff-40ad-ab89-419d0329e634",
   "metadata": {},
   "source": [
    "#### 13.5 Using pivot()\n",
    "- Transpose rows into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "eb46c896-c897-4256-9a6b-3fb3532b8f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|   900| 34|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4443c351-5cc1-49bd-8368-35040b957649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dept: string, state: string, salary: bigint]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.select('dept','state','salary')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "45066ef0-575e-4f0f-bcf7-f6fe87f84d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+\n",
      "|     dept|state|sum_salary|\n",
      "+---------+-----+----------+\n",
      "|  Finance|   NY|     16200|\n",
      "|Marketing|   NY|      9100|\n",
      "|    Sales|   CA|      8100|\n",
      "|Marketing|   CA|      8000|\n",
      "|  Finance|   CA|     18900|\n",
      "|    Sales|   NY|       900|\n",
      "+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first we group it\n",
    "df2 = df1.groupBy('dept','state').agg(F.sum('salary').alias('sum_salary'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303dcb1-b2f1-4a1e-ab89-4f73630638bf",
   "metadata": {},
   "source": [
    "Goal with pivoting:\n",
    "- to transpose state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bdd491fa-794e-4fa1-a106-0f9c6307703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|  900|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# then transpose\n",
    "df_t = df2.groupBy('dept')\\\n",
    "            .pivot('state')\\\n",
    "            .sum('sum_salary')\n",
    "\n",
    "df_t.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bcab8b-0db8-46da-bd71-c0b63d6b62c7",
   "metadata": {},
   "source": [
    "### 13.6 How to unpivot\n",
    "In spark, there is no such function as unpivot. We can do it using stack()  function in selectExpr\n",
    "\n",
    "Stack function accepts 2 argumants:\n",
    "- n: the number of rows. How many rows you want to convert\n",
    "- the stack expressions\n",
    "- i.e. sstack(n, exp, exp2....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "71bcc2ab-16b4-4520-ae8d-8e040b88cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col0|col1|\n",
      "+----+----+\n",
      "|   1|   2|\n",
      "|   3|   4|\n",
      "|   5|   6|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example first\n",
    "spark.sql(\"\"\"select stack(3, 1,2,3,4,5,6)\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "13710535-d1f9-48aa-9cf9-a2c0036cae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|  900|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert df_t into unpivoted data\n",
    "# 1. reate temp view first to you can feed to sql\n",
    "df_t.createOrReplaceTempView('tab')\n",
    "spark.sql(\"\"\" select * from tab \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f4c06efe-9ebc-46a2-90cd-f15a9155c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------+\n",
      "|     dept|    state|salary|\n",
      "+---------+---------+------+\n",
      "|    Sales|CA_newval|  8100|\n",
      "|    Sales|NY_newval|   900|\n",
      "|  Finance|CA_newval| 18900|\n",
      "|  Finance|NY_newval| 16200|\n",
      "|Marketing|CA_newval|  8000|\n",
      "|Marketing|NY_newval|  9100|\n",
      "+---------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# notice: new colname followed by column being transposed\n",
    "spark.sql(\"\"\" select dept, stack(2, 'CA_newval',CA,'NY_newval', NY ) as (state, salary) from tab\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7c1dbee7-05d0-4e23-974e-05cd1f6cba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|     dept|state|salary|\n",
      "+---------+-----+------+\n",
      "|    Sales|   CA|  8100|\n",
      "|    Sales|   NY|   900|\n",
      "|  Finance|   CA| 18900|\n",
      "|  Finance|   NY| 16200|\n",
      "|Marketing|   CA|  8000|\n",
      "|Marketing|   NY|  9100|\n",
      "+---------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a better way to do that to maintain original values are\n",
    "spark.sql(\"\"\" select dept, stack(2, 'CA',CA,'NY', NY ) as (state, salary) from tab\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "92fa18dd-378c-410e-bac4-1c96a6e76428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|     dept|state|salary|\n",
      "+---------+-----+------+\n",
      "|    Sales|   CA|  8100|\n",
      "|    Sales|   NY|   900|\n",
      "|  Finance|   CA| 18900|\n",
      "|  Finance|   NY| 16200|\n",
      "|Marketing|   CA|  8000|\n",
      "|Marketing|   NY|  9100|\n",
      "+---------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using selectExpr\n",
    "df_t.selectExpr(\"dept\", \"stack(2, 'CA',CA,'NY', NY ) as (state, salary)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cc9a9-3669-4824-8890-6ca8c923ef64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
