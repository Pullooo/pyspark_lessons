{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee9086d-fd08-42e3-823a-c03c817f3d0c",
   "metadata": {},
   "source": [
    "# Sampling and other df APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cfebea-24d1-41f7-b529-be75ae3aa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b9c7d7-7e2f-4c35-b411-a51380169995",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark Training - DF APIs\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee6929-7c38-48fc-8f70-1e9b2a8d9038",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "It is often required to analyse a large dataset with millions of rows which takes a lot of time, so it's recommended to use a random subset of data from large files. In this section, we'll discuss various sampling methods in spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ebee85-6f56-477e-ac19-db15bc732cec",
   "metadata": {},
   "source": [
    "### 1.1 sample(withReplacement=None, fraction=None, seed=None)\n",
    "- withReplacement: If true, it means the same value can occur more than once in the data\n",
    "- fraction: can be between o to 1. If 0.3 pyspark will try to get 30% or records but it's not guaranteed to be exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adef2af-a75a-4aa9-9c21-3b4fb959dc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(100)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c89824-0cea-4c35-a9f7-109c8e8db617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "| 10|\n",
      "| 16|\n",
      "| 24|\n",
      "| 27|\n",
      "| 29|\n",
      "| 36|\n",
      "| 47|\n",
      "| 51|\n",
      "| 53|\n",
      "| 56|\n",
      "| 61|\n",
      "| 68|\n",
      "| 75|\n",
      "| 80|\n",
      "| 82|\n",
      "| 88|\n",
      "| 91|\n",
      "| 95|\n",
      "| 99|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without replacement\n",
    "df.sample(fraction=0.2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6954f91b-826c-469e-9453-17b9ee8cacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  2|\n",
      "| 12|\n",
      "| 14|\n",
      "| 14|\n",
      "| 16|\n",
      "| 21|\n",
      "| 21|\n",
      "| 30|\n",
      "| 33|\n",
      "| 35|\n",
      "| 37|\n",
      "| 38|\n",
      "| 46|\n",
      "| 50|\n",
      "| 51|\n",
      "| 52|\n",
      "| 58|\n",
      "| 63|\n",
      "| 74|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with replacement\n",
    "df.sample(fraction=0.2, withReplacement=True, seed=200).show()\n",
    "# notice some values occur more than once e.g. 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe98d72-6eb7-4cb4-8156-4b641df82a15",
   "metadata": {},
   "source": [
    "### 1.2 sampleBy(self, col, fractions, seed=None)\n",
    "- Returns a stratified sample without replacement based on the fraction given on each stratum.\n",
    "- If a stratum is not specified, we treat its fraction as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f21903-1c7c-4945-beea-b429a9e8a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|key|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(100).select((F.col('id') % 3).alias('key'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "828cf931-80f8-47f5-9a79-a1e5b714ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|key|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1de9d301-2b2f-4d77-b6d5-76ae75dca0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|key|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a sample where 0 occurs 10% of the time and 1 occurs 20% of the time.\n",
    "sampled = df.sampleBy('key', fractions={0:0.1, 1:0.2}, seed=10)\n",
    "sampled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c49aac91-a4f0-4dbd-a9ba-4768e02fcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|key|count|\n",
      "+---+-----+\n",
      "|  0|    1|\n",
      "|  1|    6|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets do a groupby to see how many times each key is pulled\n",
    "sampled.groupBy('key').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4c4fa26-7ad3-4a51-8402-d9796f2f26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  null| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare input data\n",
    "data = [\n",
    "    ('James', 'Sales', 'NY', None, 34),\n",
    "    ('Alicia', 'Sales', 'NY', 8600, 56),\n",
    "    ('Robert', 'Sales', 'CA', 8100, 30),\n",
    "    ('John', 'Sales', 'AZ', 8600, 31),\n",
    "    ('Rose', 'Sales', 'AZ', 8100, 33),\n",
    "    ('Lisa', 'Finance', 'CA', 9000, 24),\n",
    "    ('Deja', 'Finance', 'CA', 9900, 40),\n",
    "    ('Sugie', 'Finance', 'NY', 8300, 36),\n",
    "    ('Ram', 'Finance', 'NY', 7900, 53),\n",
    "    ('Kyle', 'Marketing', 'CA', 8000, 25),\n",
    "    ('Reid', 'Marketing', 'NY', 9100, 50)\n",
    "]\n",
    "\n",
    "schema = ['empname', 'dept', 'state', 'salary', 'age']\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed4998-cf30-44c2-a789-00a1f8a5dbba",
   "metadata": {},
   "source": [
    "### 1.2 first(col, ingnornulls=False) /similarly last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fef6bfc-5888-45fb-b3b1-9e3a974205d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+------+---+\n",
      "|empname| dept|state|salary|age|\n",
      "+-------+-----+-----+------+---+\n",
      "|  James|Sales|   NY|  null| 34|\n",
      "| Alicia|Sales|   NY|  8600| 56|\n",
      "| Robert|Sales|   CA|  8100| 30|\n",
      "|   John|Sales|   AZ|  8600| 31|\n",
      "|   Rose|Sales|   AZ|  8100| 33|\n",
      "+-------+-----+-----+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2a6fb1-a82d-4458-ac93-0bb35afe7c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|         null|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.first(df.salary)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f225f761-a96a-40d0-bd4a-7e01c743f8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|         8600|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets see first none null values\n",
    "df.select(F.first(df.salary, ignorenulls=True)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e4047-6e9d-4f0c-bb40-b5ef99ad2f37",
   "metadata": {},
   "source": [
    "### 1.3 greatest(`*`cols) & similarly least(*)\n",
    "Returns the greatest value of the list of column names, skipping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b48192f-3c64-4f44-9e6f-fddfc152b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|greatest(salary, age)|\n",
      "+---------------------+\n",
      "|                   34|\n",
      "|                 8600|\n",
      "|                 8100|\n",
      "|                 8600|\n",
      "|                 8100|\n",
      "|                 9000|\n",
      "|                 9900|\n",
      "|                 8300|\n",
      "|                 7900|\n",
      "|                 8000|\n",
      "|                 9100|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.greatest(df.salary, df.age)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fda3d0-8b6c-4855-89e4-df680ef3db08",
   "metadata": {},
   "source": [
    "### 1.4 skewness(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a51a214-759a-41d8-8a4e-401b315aaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+------+---+\n",
      "|empname| dept|state|salary|age|\n",
      "+-------+-----+-----+------+---+\n",
      "|  James|Sales|   NY|  null| 34|\n",
      "| Alicia|Sales|   NY|  8600| 56|\n",
      "| Robert|Sales|   CA|  8100| 30|\n",
      "|   John|Sales|   AZ|  8600| 31|\n",
      "|   Rose|Sales|   AZ|  8100| 33|\n",
      "+-------+-----+-----+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72cbb1d1-143e-4e8c-80d9-dadc0dc6dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|  skewness(salary)|\n",
      "+------------------+\n",
      "|0.9433822103481873|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.skewness(df.salary)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a10bb-31d6-401c-934b-a6302724c1e5",
   "metadata": {},
   "source": [
    "### 1.5 collect_list(col)\n",
    "Returns a list of objects with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2e14e15-020c-4221-8354-480b96f399fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|collect_list(age)                           |\n",
      "+--------------------------------------------+\n",
      "|[34, 56, 30, 31, 33, 24, 40, 36, 53, 25, 50]|\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.collect_list(df.age)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12478f5-44c6-4c20-96cf-5ba643398a65",
   "metadata": {},
   "source": [
    "### `1.6 Dataframe built-in functions`\n",
    "- new column\n",
    "- encryption\n",
    "- string\n",
    "- RegExp\n",
    "- Date\n",
    "- Null\n",
    "- Collection\n",
    "- Na\n",
    "- Math & Statistician\n",
    "- Explode & Flatten\n",
    "- Formatting\n",
    "- Json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53602fb-9eb9-4136-811c-de60d451ad86",
   "metadata": {},
   "source": [
    "###  1.6.1 monotonically_increasing_id()\n",
    "- A column that generates monotonically increasing 64-bit integers\n",
    "- The generated ID is guaranteed to be monotonically increasing and unique, but not consecutive\n",
    "- `Use Case`: Create a Primary key/unique column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8b79275-17c0-4179-b232-293898e2028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  null| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4edcc315-2ac3-4cf0-997a-44f549cfdc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-----------+\n",
      "|empname|     dept|state|salary|age|         id|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "|  James|    Sales|   NY|  null| 34|          0|\n",
      "| Alicia|    Sales|   NY|  8600| 56| 8589934592|\n",
      "| Robert|    Sales|   CA|  8100| 30|17179869184|\n",
      "|   John|    Sales|   AZ|  8600| 31|17179869185|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|25769803776|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|34359738368|\n",
      "|   Deja|  Finance|   CA|  9900| 40|42949672960|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|42949672961|\n",
      "|    Ram|  Finance|   NY|  7900| 53|51539607552|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|60129542144|\n",
      "|   Reid|Marketing|   NY|  9100| 50|60129542145|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('id', F.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936ec2b-4246-4916-8eed-000f83fb9488",
   "metadata": {},
   "source": [
    "### 1.6.2 lit()\n",
    "- Create a column with a fixed/static value\n",
    "- Also useful when concatenation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8dd320c-6295-497e-a54d-0c19d20c9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-------+\n",
      "|empname|     dept|state|salary|age|country|\n",
      "+-------+---------+-----+------+---+-------+\n",
      "|  James|    Sales|   NY|  null| 34|    USA|\n",
      "| Alicia|    Sales|   NY|  8600| 56|    USA|\n",
      "| Robert|    Sales|   CA|  8100| 30|    USA|\n",
      "|   John|    Sales|   AZ|  8600| 31|    USA|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|    USA|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|    USA|\n",
      "|   Deja|  Finance|   CA|  9900| 40|    USA|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|    USA|\n",
      "|    Ram|  Finance|   NY|  7900| 53|    USA|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|    USA|\n",
      "|   Reid|Marketing|   NY|  9100| 50|    USA|\n",
      "+-------+---------+-----+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# static columns\n",
    "df.withColumn('country', F.lit('USA')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22a4f40a-afa4-4c73-9a03-b09bce7a0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-------------+\n",
      "|empname|     dept|state|salary|age|    sal_n_age|\n",
      "+-------+---------+-----+------+---+-------------+\n",
      "|  James|    Sales|   NY|  null| 34|         null|\n",
      "| Alicia|    Sales|   NY|  8600| 56|8600$ & 56yrs|\n",
      "| Robert|    Sales|   CA|  8100| 30|8100$ & 30yrs|\n",
      "|   John|    Sales|   AZ|  8600| 31|8600$ & 31yrs|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|8100$ & 33yrs|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|9000$ & 24yrs|\n",
      "|   Deja|  Finance|   CA|  9900| 40|9900$ & 40yrs|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|8300$ & 36yrs|\n",
      "|    Ram|  Finance|   NY|  7900| 53|7900$ & 53yrs|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|8000$ & 25yrs|\n",
      "|   Reid|Marketing|   NY|  9100| 50|9100$ & 50yrs|\n",
      "+-------+---------+-----+------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenating values\n",
    "df.withColumn('sal_n_age', F.concat('salary', F.lit('$ & '),'age',F.lit('yrs'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c5df2-5df8-4f7d-9b8a-bae432ba0d2a",
   "metadata": {},
   "source": [
    "### 1.6.3 expr(str)\n",
    "- Takes an SQL expression as string argument, executes the expression and returns a column Type\n",
    "- We can use SQL-like functions that are not present in pyspark column type and built-in functions (pyspark.sql.functions) e.g. `CASE WHEN`, `Concat operator` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79bf1b47-1307-4c60-a423-470849e69a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-----------+\n",
      "|empname|     dept|state|salary|age|empname_len|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "|  James|    Sales|   NY|  null| 34|          5|\n",
      "| Alicia|    Sales|   NY|  8600| 56|          6|\n",
      "| Robert|    Sales|   CA|  8100| 30|          6|\n",
      "|   John|    Sales|   AZ|  8600| 31|          4|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|          4|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|          4|\n",
      "|   Deja|  Finance|   CA|  9900| 40|          4|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|          5|\n",
      "|    Ram|  Finance|   NY|  7900| 53|          3|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|          4|\n",
      "|   Reid|Marketing|   NY|  9100| 50|          4|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use case 1\n",
    "df.withColumn('empname_len', F.expr(\"length(empname)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b178155e-778d-4a45-8c8b-6daa7c9e53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+----------+\n",
      "|empname|     dept|state|salary|age|age_groups|\n",
      "+-------+---------+-----+------+---+----------+\n",
      "|  James|    Sales|   NY|  null| 34|     adult|\n",
      "| Alicia|    Sales|   NY|  8600| 56|    senior|\n",
      "| Robert|    Sales|   CA|  8100| 30|     adult|\n",
      "|   John|    Sales|   AZ|  8600| 31|     adult|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|     adult|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|     adult|\n",
      "|   Deja|  Finance|   CA|  9900| 40|     adult|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|     adult|\n",
      "|    Ram|  Finance|   NY|  7900| 53|    senior|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|     adult|\n",
      "|   Reid|Marketing|   NY|  9100| 50|     adult|\n",
      "+-------+---------+-----+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use case 2\n",
    "df.withColumn('age_groups', F.expr(\"case when age > 50 then 'senior' else 'adult' end\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e992b07-eec9-4be8-8386-6a1c06834d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-----------+\n",
      "|empname|     dept|state|salary|age|age_plus_10|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "|  James|    Sales|   NY|  null| 34|         44|\n",
      "| Alicia|    Sales|   NY|  8600| 56|         66|\n",
      "| Robert|    Sales|   CA|  8100| 30|         40|\n",
      "|   John|    Sales|   AZ|  8600| 31|         41|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|         43|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|         34|\n",
      "|   Deja|  Finance|   CA|  9900| 40|         50|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|         46|\n",
      "|    Ram|  Finance|   NY|  7900| 53|         63|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|         35|\n",
      "|   Reid|Marketing|   NY|  9100| 50|         60|\n",
      "+-------+---------+-----+------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use case 3\n",
    "df.withColumn('age_plus_10', F.expr(\"age + 10\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccc4f3-5b29-45d8-8632-9d4161702e97",
   "metadata": {},
   "source": [
    "### 1.6.4 spark_partition_id()\n",
    "- Generates a column with partition ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa2192cb-6032-412e-986d-e35b131b2f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.range(10)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6df552f8-3b07-47da-a6bc-a3c9e744a2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.repartition(5)\n",
    "df1.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bb00977-acf5-440e-ad77-1f9681bdc34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|SPARK_PARTITION_ID()|\n",
      "+---+--------------------+\n",
      "|  3|                   0|\n",
      "|  0|                   1|\n",
      "|  1|                   1|\n",
      "|  4|                   1|\n",
      "|  7|                   2|\n",
      "|  8|                   2|\n",
      "|  5|                   3|\n",
      "|  6|                   3|\n",
      "|  9|                   3|\n",
      "|  2|                   4|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since we have 5 partitions, 5 partition ids will be created\n",
    "df1.select('id', F.spark_partition_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708e71e-4f4d-401c-9c29-c480c9b8ffb5",
   "metadata": {},
   "source": [
    "### 1.6.5 rand(seed) and randn(seed)\n",
    "- `rand:` Generates a column with independent and identically distributed (iid) samples from uniform distribution (constant freqs)\n",
    "- `randn:` generates a column with independent and identically distributed (iid) samples from a standard normal distribution (bell shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3be57758-e6e1-418e-a4b3-5e8216473bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+-------------------+\n",
      "|empname|dept     |state|salary|age|rand_col           |\n",
      "+-------+---------+-----+------+---+-------------------+\n",
      "|James  |Sales    |NY   |null  |34 |0.9686366478115398 |\n",
      "|Alicia |Sales    |NY   |8600  |56 |0.7578638408379902 |\n",
      "|Robert |Sales    |CA   |8100  |30 |0.9142913539241686 |\n",
      "|John   |Sales    |AZ   |8600  |31 |0.6124331254386841 |\n",
      "|Rose   |Sales    |AZ   |8100  |33 |0.3576198156706625 |\n",
      "|Lisa   |Finance  |CA   |9000  |24 |0.28526473713733846|\n",
      "|Deja   |Finance  |CA   |9900  |40 |0.8358218713663149 |\n",
      "|Sugie  |Finance  |NY   |8300  |36 |0.7937570767235927 |\n",
      "|Ram    |Finance  |NY   |7900  |53 |0.3876281875521618 |\n",
      "|Kyle   |Marketing|CA   |8000  |25 |0.25100516160693154|\n",
      "|Reid   |Marketing|NY   |9100  |50 |0.8977705819290853 |\n",
      "+-------+---------+-----+------+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only positive values\n",
    "df.withColumn('rand_col', F.rand(seed=70)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a817ba85-e3e2-483c-9b8d-1a2ba732733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+--------------------+\n",
      "|empname|     dept|state|salary|age|           rand_norm|\n",
      "+-------+---------+-----+------+---+--------------------+\n",
      "|  James|    Sales|   NY|  null| 34|  0.5879349573780887|\n",
      "| Alicia|    Sales|   NY|  8600| 56|-0.24527770770278648|\n",
      "| Robert|    Sales|   CA|  8100| 30| -0.6046413008367373|\n",
      "|   John|    Sales|   AZ|  8600| 31|-0.35642077694085117|\n",
      "|   Rose|    Sales|   AZ|  8100| 33|  1.0779880693130197|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|-0.41863979724682465|\n",
      "|   Deja|  Finance|   CA|  9900| 40| -0.6200861214441888|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|  0.6094312221458198|\n",
      "|    Ram|  Finance|   NY|  7900| 53|-0.16990689230803258|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|0.003890795511576...|\n",
      "|   Reid|Marketing|   NY|  9100| 50| -0.8070887599283788|\n",
      "+-------+---------+-----+------+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# both positive and negative values\n",
    "df.withColumn('rand_norm', F.randn(seed=90)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aaf4b6-41fa-41b9-b8b2-0c9afd41282c",
   "metadata": {},
   "source": [
    "### 2. String Manipulation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafd339-e9a5-45b4-a95c-006ca816fc9c",
   "metadata": {},
   "source": [
    "### 2.1 split(str, pattern)\n",
    "- Splits str around patern (pattern is a regular expression)\n",
    "- Can be used to extract positional elements from delimited fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b997bc6d-f670-4288-84fd-38d5e4e1149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord = spark.read.load('PracticeFiles/Orders', sep=',', format='csv', schema=('order_id int,order_date timestamp, order_customer_id int, order_status string'))\n",
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9754820-c06f-43b3-aaf3-062fc3c7dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|         order_date|     order_date_list|\n",
      "+-------------------+--------------------+\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:...|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:...|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:...|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:...|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use case 1\n",
    "ord.select('order_date', F.split(ord.order_date, pattern='-').alias('order_date_list')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df585e70-1ac4-4201-b635-18829448184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|         order_date|order_year|\n",
      "+-------------------+----------+\n",
      "|2013-07-25 00:00:00|      2013|\n",
      "|2013-07-25 00:00:00|      2013|\n",
      "|2013-07-25 00:00:00|      2013|\n",
      "|2013-07-25 00:00:00|      2013|\n",
      "|2013-07-25 00:00:00|      2013|\n",
      "+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract first element of list created from split\n",
    "ord.select('order_date', F.split(ord.order_date, pattern='-')[0].alias('order_year')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3f7da7f-f5d6-4190-b596-68dc8c3e3c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|             s|\n",
      "+--------------+\n",
      "|abc2cd23fe27kI|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use case 2\n",
    "df1 = spark.createDataFrame([('abc2cd23fe27kI',)], ['s',])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69a6e582-0391-409a-8e6c-e2c904a2ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|split(s, [0-9]+, -1)|\n",
      "+--------------------+\n",
      "|   [abc, cd, fe, kI]|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(F.split(df1.s, '[0-9]+')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ad868-1feb-4b78-9537-44b80183d6e7",
   "metadata": {},
   "source": [
    "### 2.2 length(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5cdd0200-2398-4a5d-9119-cf2438b752ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|length_status|\n",
      "+--------+-------------------+-----------------+---------------+-------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|            6|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|           15|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|            8|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|            6|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|            8|\n",
      "+--------+-------------------+-----------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('length_status', F.length(ord.order_status)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df0fa8-3612-421b-9b9e-89388126fae8",
   "metadata": {},
   "source": [
    "### 2.3 lower(col), upper(col), initcap(col)\n",
    "- `initcap():` capitalises first letter in a string, and leave others in lower case. Similar to propcase\n",
    "- Same as with other languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "725d7d8d-898e-424b-abec-d341f2853206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|       init_cap|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         Closed|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|Pending_payment|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       Complete|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         Closed|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       Complete|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('init_cap', F.initcap(ord.order_status)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b373b6-fc1c-4053-a730-c2d37695ebeb",
   "metadata": {},
   "source": [
    "### 2.3 ltrim(col), rtrim(col), trim(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b39e4668-db37-45dd-9958-af08142c55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            col1|\n",
      "+----------------+\n",
      "|          spark |\n",
      "|   developer    |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame([('  spark ',), ('   developer    ',)], schema=['col1'])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4f9a0-ebf8-47a1-9125-d175336a40c7",
   "metadata": {},
   "source": [
    "Notice the presence of leading and trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d9f3c36-e033-4958-9b41-ac77b05b72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|            col1|trimmed_value|\n",
      "+----------------+-------------+\n",
      "|          spark |        spark|\n",
      "|   developer    |    developer|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn('trimmed_value', F.trim('col1')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1695f2b-b708-477f-9ce6-637c75d8cbcf",
   "metadata": {},
   "source": [
    "### 2.4 lpad(col, len, pad), rpad(col, len, pad)\n",
    "Pads the string columns to width 'len' with 'pad'\n",
    "\n",
    "`e.g:` in the order df, convert order_id to a field with length 10 by padding zeros to the left (front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "07133c97-e372-46f7-8380-3e1b4c81c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "63485269-d9fd-440e-9b26-a9764683999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|   padding|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|0000000001|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|0000000002|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|0000000003|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('padding', F.lpad(ord.order_id, len=10, pad='0')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453bb4e-ef7d-4598-86d7-a3e127d4c4a0",
   "metadata": {},
   "source": [
    "### 2.5 reverse(col)\n",
    "- Returns a reversed string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54ac6e20-0ed2-47ba-ae7b-1ddc549b9f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|reversed_status|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         DESOLC|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       ETELPMOC|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('reversed_status', F.reverse(ord.order_status)).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92fd39-091d-4b69-bc29-9ece2349de0f",
   "metadata": {},
   "source": [
    "### 2.6 repeat(col, n)\n",
    "- Repeats a string column n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4e3e0bf4-3d58-434a-96d9-e43b769fdcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |repeat_status                                |\n",
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |CLOSEDCLOSEDCLOSED                           |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('repeat_status', F.repeat(ord.order_status, n=3)).show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b30f9-166c-4754-b2c8-d59018d9a499",
   "metadata": {},
   "source": [
    "### 2.7 hex(col)\n",
    "- Computes hex value of a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "050767a9-4b77-475e-9007-cb35766c7ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |hex                           |\n",
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |434C4F534544                  |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |434F4D504C455445              |\n",
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('hex', F.hex(ord.order_status)).show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215d026-1317-4fbd-8587-a6a2a0d82c4f",
   "metadata": {},
   "source": [
    "#### 2.8 concat(*cols)\n",
    "concatenates multiple columns together into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a609b6e4-6753-422d-b0d2-92cb27c46771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "573a631a-87cb-4423-b2f9-ca258431ea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|        IDStatus|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         1CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       3COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         4CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       5COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - concatenate order id and status\n",
    "ord.withColumn('IDStatus', F.concat('order_id','order_status')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "184355ff-2b52-4e69-8869-3395d2c67622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|         IDStatus|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         1 CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2 PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       3 COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         4 CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       5 COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - concatenate order id to status keeping a space between them\n",
    "ord.withColumn('IDStatus', F.concat('order_id', F.lit(' '), 'order_status')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fd6ed-9d8e-4892-be10-22e351c3e1cb",
   "metadata": {},
   "source": [
    "#### 2.9 concat_ws(sep, *cols)\n",
    "- Similar to concat() but this allows you to provide a separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0b5edd4c-1329-4997-ab53-a8b3f74a8ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|         IDStatus|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         1 CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2 PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       3 COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         4 CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       5 COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('IDStatus', F.concat_ws(' ',  'order_id','order_status')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c0c7a-139a-4151-aed9-e7a0d6353e9c",
   "metadata": {},
   "source": [
    "#### 2.10 substring(str, pos, len)\n",
    "- Starts retrieving substring from pos and is of length len\n",
    "- Unlike sql and SAS where this only works on columns of type string (and not date fields), here this works on any column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d8753c8-db17-4f7f-aeef-95ed3e9e6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task - extract the date part of order_date\n",
    "# notice this has a type = timestamp\n",
    "ord.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f31d3ea9-f9d4-432b-aacb-0ce41a39383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|order_year|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013-07-25|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013-07-25|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013-07-25|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013-07-25|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013-07-25|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('order_year', F.substring('order_date',1,10)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cee5f5-5288-4959-bcaf-f51ff3ca84e0",
   "metadata": {},
   "source": [
    "#### 2.11 substring_index(str, delim, count)\n",
    "- Returns the substring from string str before counting occurences of the delimiter - delim\n",
    "- If count > 0, everything to the left of the delimiter is returned\n",
    "- If coung < 0, everything to the right of the final delimiter (counting from the right) is returned\n",
    "- substring_index performs a case-sensitive match when searching for delim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5c77ab75-6be3-4f71-97e7-721f73871a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9499d61a-c083-41fd-9ea7-b600576c4a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|dummy|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED| 2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT| 2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE| 2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED| 2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE| 2013|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1: split order date field by hyphen, and select the first element\n",
    "ord.withColumn('dummy', F.substring_index(ord.order_date, '-', 1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56e7e9fa-5e4d-468f-9356-86956ee99ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|  dummy|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013-07|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013-07|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013-07|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013-07|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013-07|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2: split order date field by hyphen, and select the first 2 elements\n",
    "ord.withColumn('dummy', F.substring_index(ord.order_date, '-', 2)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a77e-d1ed-4929-8844-33d3d95efd4b",
   "metadata": {},
   "source": [
    "#### 2.12 instr(str, substr)\n",
    "- Locates the position of the first occurence of subtr column in the given string\n",
    "- Returns null if either of the arguments are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3013f2af-82f4-4e19-a0fb-4a782bd006dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|instr|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    0|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    8|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    0|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    0|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    0|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Find the position of the first occurence of '_' in order_status\n",
    "ord.withColumn('instr', F.instr('order_status', '_')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7a7d9-5097-4df6-bb42-59482d706763",
   "metadata": {},
   "source": [
    "#### 2.13 locate(substr, str, pos=1)\n",
    "- locate the position of the first occurence of substr in a string column, after position pos\n",
    "- 1 based (rather than 0 based) indexing used.\n",
    "- 0 returned if substr not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0074519a-058a-4787-b133-65081b2695ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|locate|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    12|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    12|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    12|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    12|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    12|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('locate', F.locate('00', 'order_date', 1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d90b8dbe-ed67-4a36-8b30-019bea66387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|locate|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    15|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    15|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    15|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    15|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    15|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('locate', F.locate('00', 'order_date', 15)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ab7ec-a9a7-4ee5-98e5-9a875427bbc9",
   "metadata": {},
   "source": [
    "#### 2.14 translate(srcCol, matching, replace):\n",
    "translate any character in the srcCol by a character in 'matching'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "af0b36a3-593d-4381-a9d0-1ddbbc55acf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      col|\n",
      "+---------+\n",
      "|translate|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('translate',)], ['col',])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ee332-0d2a-4d48-8f14-283730fc204f",
   "metadata": {},
   "source": [
    "Task:\n",
    "- within the col field, mate the following strings with the following values: 'r' with 1, 'n' with 2, 'l' with 3, 't' with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ffa76a69-0ca1-476d-9280-d0e5fffaab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------+\n",
      "|      col|translate(col, rnlt, 123)|\n",
      "+---------+-------------------------+\n",
      "|translate|                  1a2s3ae|\n",
      "+---------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.col, F.translate(df.col, 'rnlt', '123')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5980b44-8cd0-4f28-8e84-7f5597a21a71",
   "metadata": {},
   "source": [
    "#### 2.15 overlay(src, replace, pos, len)\n",
    "- New in version 3\n",
    "- overlays the specified portion of 'src' with 'replace' starting with the byte position 'pos' of 'src' and proceeding for 'len' bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7257d-131e-4779-885a-40b4e8f47f9e",
   "metadata": {},
   "source": [
    "# 3. RegExp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9ccaa-d124-4d81-babc-d067e430323c",
   "metadata": {},
   "source": [
    "### 3.1 regexp_extract(str, pattern, idx)\n",
    "- Used to extract regex pattern - pattern - from 'str'\n",
    "- idx = which group to extract. if 1 ==> we extract the first matching group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a7602dc6-45dc-46ba-90e8-f0e8fd70f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|     str|\n",
      "+--------+\n",
      "|11ss1 ab|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=[('11ss1 ab',)], schema=['str'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "280cd885-463a-4f40-9eb8-d45f20a2fd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|     str|extract_digits|\n",
      "+--------+--------------+\n",
      "|11ss1 ab|            11|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 1: retrieve first set of digits\n",
    "df.withColumn('extract_digits', F.regexp_extract(df.str, '(\\d+)', 1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eb96b2f1-0153-4c64-a5b3-df32a95142d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|     str|extract_letters|\n",
      "+--------+---------------+\n",
      "|11ss1 ab|             11|\n",
      "+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 2: retrieve set of letters followed by alphabest\n",
    "df.withColumn('extract_letters', F.regexp_extract(df.str, '(\\d+)(\\w+)', 1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30268f-f584-46ae-ab3f-4649f2d997d3",
   "metadata": {},
   "source": [
    "### 3.2 regexp_replace(str, pattern, replacement)\n",
    "- Replaces a column value with a string for another string or substrin\n",
    "- empty string returned if no match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7563c45-ec8d-415c-b821-79f64d1f7b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|     str|regexp_replace|\n",
      "+--------+--------------+\n",
      "|11ss1 ab|   XXXXssXX ab|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task1: replace all digits with XX\n",
    "df.withColumn('regexp_replace', F.regexp_replace(df.str, ('\\d'), 'XX')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "54603d10-9e0c-46f5-8a87-b8f48df71d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|     str|regexp_replace|\n",
      "+--------+--------------+\n",
      "|11ss1 ab|      XXss1 ab|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 2: replace all double digits with XX\n",
    "df.withColumn('regexp_replace', F.regexp_replace(df.str, ('\\d\\d'), 'XX')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5db3610e-84c5-438c-bb74-a64a3cf6d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+--------+\n",
      "|id |addr                     |city    |\n",
      "+---+-------------------------+--------+\n",
      "|1  |2625 Oxford University Rd|Phoenix |\n",
      "|2  |1234 Thomas St           |Glendale|\n",
      "+---+-------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "addr = [(1, '2625 Oxford University Rd', 'Phoenix'), (2, \"1234 Thomas St\", \"Glendale\")]\n",
    "df=spark.createDataFrame(addr, ['id','addr','city'])\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6dfe3851-72b5-487c-8366-9b996416790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+--------+---------------------------+\n",
      "|id |addr                     |city    |new_addr                   |\n",
      "+---+-------------------------+--------+---------------------------+\n",
      "|1  |2625 Oxford University Rd|Phoenix |2625 Oxford University Road|\n",
      "|2  |1234 Thomas St           |Glendale|1234 Thomas Street         |\n",
      "+---+-------------------------+--------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Replace every occurence of 'Rd' with 'Road' and 'St' with 'Street' in the address field\n",
    "df.withColumn('new_addr', F.when(df.addr.endswith('Rd'), F.regexp_replace(df.addr, 'Rd', 'Road'))\\\n",
    "                           .when(df.addr.endswith('St'), F.regexp_replace(df.addr, 'St', 'Street'))\\\n",
    "                           .otherwise(df.addr))\\\n",
    "                           .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213c087-aa35-44b9-9c85-9398b0e448c7",
   "metadata": {},
   "source": [
    "### 3.3 rlike()\n",
    "- Not a dataframe function but a column function to check if a pattern is found or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bd0b0b81-ab0e-4207-827a-d64e850bbaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+\n",
      "| id|                addr|    city|\n",
      "+---+--------------------+--------+\n",
      "|  1|2625 Oxford Unive...| Phoenix|\n",
      "|  2|      1234 Thomas St|Glendale|\n",
      "+---+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "39ec5ccc-baca-4629-a6c9-b32eff1c60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------+\n",
      "|addr                     |addr RLIKE (\\d)|\n",
      "+-------------------------+---------------+\n",
      "|2625 Oxford University Rd|true           |\n",
      "|1234 Thomas St           |true           |\n",
      "+-------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.addr, df.addr.rlike('(\\d)')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c8a8b-c6f6-470e-a9f6-ccb3c8706f23",
   "metadata": {},
   "source": [
    "# 4. Null Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "06315fcb-4777-4d98-b6a6-f1b2066887de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+-----+\n",
      "|  name|  id|phone|stAdd|\n",
      "+------+----+-----+-----+\n",
      "|Robert|   1| null|114.0|\n",
      "|  John|null| 2577|  NaN|\n",
      "+------+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('Robert', 1, None, 114.0), ('John', None, 2577, float('nan'))], ('name', 'id', 'phone', 'stAdd'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5663f-5fc8-475e-96de-86c7d216f6c2",
   "metadata": {},
   "source": [
    "### 4.1 isnull(col)\n",
    "- Returns true if the column is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a8d7aa8c-8525-4723-a4ff-42e9e29f1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|phone|(phone IS NULL)|\n",
      "+-----+---------------+\n",
      "| null|           true|\n",
      "| 2577|          false|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('phone', F.isnull(df.phone)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149515e-f418-458e-93bb-c76d65dade98",
   "metadata": {},
   "source": [
    "### 4.2 isnan(col)\n",
    "Returns true if the column is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68662b66-65f0-4678-8aa2-25963928fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|stAdd|isnan(stAdd)|\n",
      "+-----+------------+\n",
      "|114.0|       false|\n",
      "|  NaN|        true|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('stAdd', F.isnan('stAdd')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83bf85-14ad-4d91-b5e6-31abebde2b48",
   "metadata": {},
   "source": [
    "### `4.3 nanvl(col1, col2)`\n",
    "- similar to the coalesce function (which is limited in scope in pyspark)\n",
    "- If col1 has a value, it will return it. Else it returns value in col2\n",
    "- Not a value in this case = NaN or null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c824b9af-52bf-4164-a8b3-c9a8a5ae898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------------------+\n",
      "|stAdd|phone|nanvl(stAdd, phone)|\n",
      "+-----+-----+-------------------+\n",
      "|114.0| null|              114.0|\n",
      "|  NaN| 2577|             2577.0|\n",
      "+-----+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('stAdd', 'phone', F.nanvl('stAdd', 'phone')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d14bd-7252-4055-849d-810548e6c2ee",
   "metadata": {},
   "source": [
    "### 4.4 coalesce(*cols)\n",
    "- Returns the first column that is not null\n",
    "- `wierd`: NaN is treated as a value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fae5bf94-dae4-4e4d-a28c-77641d979684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------------------+\n",
      "|stAdd|phone|coalesce(stAdd, phone)|\n",
      "+-----+-----+----------------------+\n",
      "|114.0| null|                 114.0|\n",
      "|  NaN| 2577|                   NaN|\n",
      "+-----+-----+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('stAdd', 'phone', F.coalesce('stAdd', 'phone')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfd84b-2eb2-404e-b8b3-53e2dd72b2a2",
   "metadata": {},
   "source": [
    "## 5. na Functions\n",
    "Used to work with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f954d-505e-44fe-88ac-511d777504a4",
   "metadata": {},
   "source": [
    "### 5.1 drop(how='any', thresh=None, subset=None)\n",
    "- Removes rows with Null values\n",
    "- Thresh: if specified, drop rows that have less than 'thresh' non-null values. This overwrites the 'how' parameter\n",
    "- Subset: optional list of column names to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "61afd430-f28a-4adc-8f33-eba7559a65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Alice', 80, 10), ('Bob', None, 5), ('Tom', 50, 50), (None, None, None), ('Robert', 30, 35)]\n",
    "schema = 'name string, Age int, height int'\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d22220c2-743e-40c0-b4ef-061dd7ff26a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|Age|height|\n",
      "+------+---+------+\n",
      "| Alice| 80|    10|\n",
      "|   Tom| 50|    50|\n",
      "|Robert| 30|    35|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop every record with null values\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "929c2744-36de-446e-8aaf-2eab770688b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop records with less than 1 non-null values (i.e. atleast one present value)\n",
    "df.na.drop(thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "13dcdb87-a750-4ef3-8bd4-e757aac7facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|Age|height|\n",
      "+------+---+------+\n",
      "| Alice| 80|    10|\n",
      "|   Tom| 50|    50|\n",
      "|Robert| 30|    35|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop records with less than 1 non-null values (i.e. atleast one present value)\n",
    "df.na.drop(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "68145729-40f4-4235-9139-8e4a93ec7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5b9905e6-a09c-441d-9362-b634146b1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|Age|height|\n",
      "+------+---+------+\n",
      "| Alice| 80|    10|\n",
      "|   Tom| 50|    50|\n",
      "|Robert| 30|    35|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# every row(not column) which has a null value in age will be dropped\n",
    "df.na.drop(subset='age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "53d213c1-394c-4cda-a66b-db89ef29365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# every row(not column) which has a null value in height will be dropped\n",
    "df.na.drop(subset='height').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382a47b-2bfe-41b9-addd-f059b1aa4777",
   "metadata": {},
   "source": [
    "### 5.2 fill(value, subset=None)\n",
    "- Replace null values\n",
    "- value: value to replace null values with\n",
    "- subset: optional list of column names to consider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a5739946-a5ca-49f4-b975-641c6afb5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74191c6-a88d-4b04-9536-6975757ed948",
   "metadata": {},
   "source": [
    "Note:\n",
    "- if you fill in na for the whole df with integers, then that will only be applied to the numeric fields\n",
    "- If you fill with string, that will only be applied to the non-numeric fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0931ec72-8e40-4b64-8d22-639654fb277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|Age|height|\n",
      "+------+---+------+\n",
      "| Alice| 80|    10|\n",
      "|   Bob| 50|     5|\n",
      "|   Tom| 50|    50|\n",
      "|  null| 50|    50|\n",
      "|Robert| 30|    35|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1: only fill numeric columns \n",
    "df.na.fill(50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "96f65cca-ffa6-4234-8740-d0c6acdfa4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|jayjay|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2: only fill string columns filled\n",
    "df.na.fill('jayjay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e3092079-78f3-4178-bebd-7ffec49d179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|Age|height|\n",
      "+------+---+------+\n",
      "| Alice| 80|    10|\n",
      "|   Bob| 50|     5|\n",
      "|   Tom| 50|    50|\n",
      "|  null| 50|  null|\n",
      "|Robert| 30|    35|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3: only fill 'age'\n",
    "df.na.fill({'Age':50}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca685e-c2bf-4f42-abce-291562bfda24",
   "metadata": {},
   "source": [
    "### 5.3 replace(to_replace, value=<no value>, subset=None)\n",
    "- can be used to replace null values, but has a wider use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f83a2e26-963d-4bad-ae0c-d7b8582b8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6e9b5721-f35a-4283-a8a6-ec65afb04b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "| Alice|  80|    10|\n",
      "|   Bob|null|     5|\n",
      "|   Tom|  99|    99|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 1: replace 80 with 99\n",
    "df.na.replace(50, 99).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "84a2ad5c-dcf5-4cc8-9575-e99e0b67fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| Age|height|\n",
      "+------+----+------+\n",
      "|  Alex|  80|    10|\n",
      "|   Cob|null|     5|\n",
      "|   Tom|  50|    50|\n",
      "|  null|null|  null|\n",
      "|Robert|  30|    35|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 2 beyond nulls: within the name field, replace Alice with Alex and Bob with Cob\n",
    "df.replace({'Alice': 'Alex', 'Bob':'Cob'}, subset='name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85210c5c-cf14-4c9a-b6a6-808529b3ef35",
   "metadata": {},
   "source": [
    "### 6. Mathematics and Statistics Functions\n",
    "- Import these from pyspark.sql.functions module\n",
    "- `abs(col)`\n",
    "- `exp(col)`\n",
    "- `factorial(col)`\n",
    "- `sqrt(col)`\n",
    "- `cbrt(col)`: cube root of a value\n",
    "- `pow(col, n)`\n",
    "- `floor(col)`\n",
    "- `ceil(col)`\n",
    "- `round(col, scale=0)`\n",
    "- `trunc(col, format):` can apply on a date or timestamp field\n",
    "- `signum():`returns 1 if n > 0, 0 if n = 0, -1 if n < 0\n",
    "- `avg(), sum(), sumDistinct(col), mean(col), Count(col), min(col), max(col)`\n",
    "- `countDistinct(col)`\n",
    "- `corr(col1, col2):` returns Pearson Correlation Coefficient\n",
    "- `covar_pop(col1, col2):` returns population covariance\n",
    "- `covar_samp(col1, col2):` Returns the sample covariance\n",
    "- `var_pop(col):` Return shte population variance of the values in a group\n",
    "- `var_samp(col):` Returns the unbiased variance of the values in a group\n",
    "- `variance(col):` Returns the population variance of the values in a group\n",
    "- `stddev(col):` Returns the unbiased sample standard deviation of the expression in a group\n",
    "- `stddev_pop(col):` Returns the population standard deviation of the expression in a group\n",
    "- `stddev_samp(col):` Returns the unbiased sample standard deviation of the expression in a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "876b728a-7e59-44d4-82f1-e184cdaa7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3b13239e-5117-4ac9-bec5-deca089951f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------+\n",
      "|count(DISTINCT order_status)|round(corr(order_id, order_customer_id), 5)|\n",
      "+----------------------------+-------------------------------------------+\n",
      "|                           9|                                    0.00159|\n",
      "+----------------------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(F.countDistinct('order_status'), F.round(F.corr('order_id', 'order_customer_id'),5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64942e-9d6f-4650-9d88-ac0f4d06f384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
